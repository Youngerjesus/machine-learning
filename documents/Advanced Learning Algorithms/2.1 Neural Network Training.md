# Neural Network Training

## TensorFlow Implementation 

- 텐서플로우를 통해서 모델 학습 시키는 것에 대해서 다룸.
  - 모델 구조를 지정해서 추론을 위한 계산 방식 지정 
  - cost function 을 통해서 모델을 컴파일 
  - 지정된 cost function 과 데이터 셋을 이용해서 모델을 훈련 

![](../images/train%20neural%20network%20in%20tensorflow.png)

- Step 1 은 모델을 지정하는 거고, 어떻게 inference (= predict) 를 할건지 지정하는 것.
  - model 을 compile 할 때 중요한 건 loss function 을 지정하는 것.
- Step 2 는 model 을 compile 하는 것. loss function 을 지정해서.
  - model 을 fit 할 떈 데이터들을 입력하고 얼마나 gradient descent 를 적용할 건지를 입력해야함.
- Step 3 는 model d을 훈련하는 것. 

## Training Detail

- TensorFlow 는 input 과 parameter 를 이용해서 출력을 계산하고, 지정한 Cost function 을 통해서 오차를 계산하고, 이를 최적화하는 과정을 자동화한다.
  - 이 과정을 코드로 짜는 법을 배웠다.  
  
- TensorFlow code 에서 무슨 일이 일어나고 있는지 설명하는 것. 
  - model 의 추론은 어디서 일어나고
  - cost function 과 loss function 의 명시는 어디서 하는지. 
  - gradient descent 가 어디서 일어나고 

- 다음에는 activation function 을 지정해서 Neural Network 의 성능을 올리는 법에 대해서 알아보겠다. 

![](../images/model%20training%20steps.png)

- 이 Neural Network 의 TensorFlow 코드가 이전에 logistic regression 에서 학습하던 거랑 유사하다.
  - 1) Model 이 어떻게 inference 하는지 명시하는 것. (모델의 생성) 
  - 2) loss function 과 cost function 을 지정하는 것. 
  - 3) data 를 기반으로 학습하는 것. (gradient descent) 

![](../images/crate%20model%20in%20neural%20network.png)

![](../images/cost%20and%20loss%20function%20in%20nerual%20network.png)

- 아 logistic regression 에서 지정한 loss function 이 실제 이름이 binaryCrossEntropy function 이구나.
- classification 문제 대신에 다른 문제를 neural network 에서 풀고 싶다면 다른 Loss Function 을 쓰면 된다.
  - ex) Linear Regression 에서는 MeanSquaredError() 

- 여기서는 J(W, B) 를 cost function 으로 표기함.
- neural network 에서의 cost function 은 모든 파라미터들을 포함한 function 이다. (모든 레이어를 포함.)
- fW,B(X vector) 는 신경망에서 output 을 내는 모든 파라미터와 연관되어있는 함수로 표기함.

![](../images/gradient%20descent%20in%20neural%20network.png)

- gradient descent 를 적용하기 위해서 중요한 건 편미분 (partial derivative) 를 이용하는 것이다. 
  - 보편적으로 신경망에선 backpropagation 이라는 것을 이용해서 계산한다.
    - 이건 `model.fit()` 함수 안에서 계산된다는 듯.
